\chapter{Background}

\section{What is a Channel?} % -----------------------------------------------
The Channel Archiver deals with Channels that are served by EPICS
ChannelAccess. It stores all the information available via ChannelAccess:
\begin{itemize}
\item Time Stamp
\item Status/Severity
\item Value
\item Meta information:\\
      Units, Limits, ... for numeric channels,
      enumeration strings for enumerated channels.
\end{itemize}

\noindent The archiver stores the original \INDEX{time stamps} as it receives
them from ChannelAccess. It cannot check if these time stamps are valid, except
that it refuses to go ``back in time'' because it can only append new
values to the end of the data storage. It is therefore imperative to
properly configure the data sources, that is: the clocks on the CA
servers.

\label{back:in:time}
\NOTE If the CA server provides bad time stamps, for example stamps
that are older than values which are already in the archive, or stamps
that are unbelievably far ahead in the future, the ArchiveEngine will log
a warning message and refuse to store the affected samples.
This is a common reason for ``Why is there no data in my archive?''

As for the values themselves, the native data type of the channel as
reported by ChannelAccess is stored. For those familiar with the
ChannelAccess API, this means:
Channels that report a native data type of DBR\_xxx\_ are stored as
DBR\_TIME\_xxx after once requesting the full DBR\_CTRL\_xxx information.
 The Archiver can therefore handle scalar and array numerics
(double, int, ...), strings and enumerated types. 

\section{Data Sources} % -----------------------------------------------------
Before even considering the available \INDEX{sampling options}, it is
important to understand the \INDEX{data sources}, the \INDEX{ChannelAccess
servers} whose channels we intend to archive.
In most cases we will archive channels served by an EPICS Input/Output
Controller (\INDEX{IOC}) which is configured via a collection of EPICS
\INDEX{records}.
Alternatively, we can archive channels served by a custom-designed CA
server that utilizes the portable CA library \INDEX{PCAS}.
In those cases, one will have to contact the implementor of the custom
CA server for details.
In the following, we concentrate on the IOC scenario and use the
analog input record from listing~\ref{lst:airecord} as an example.

\lstinputlisting[float=htb,caption={``aiExample'' record},label=lst:airecord]{aiexample.db} 

\noindent What happens when we try to archive the channel ``aiExample''?
We will receive updates for the record's value field (VAL). In fact we
might as well have configured the archiver to use ``aiExample.VAL''
with exactly the same result.
The record is scanned at 10~Hz, so we can expect 10 values per second.
Almost: The archive deadband (ADEL) limits the values that we receive
via CA to changes beyond 0.1. When archiving this channel, we could
store at most 10 values per second or try to capture every change,
utilizing the ADEL configuration to limit the network traffic.

\NOTE The archiver has no knowledge of the scan rate nor the deadband
configuration of your data source! You have to consult the IOC
database or PCAS-based code to obtain these.

With each value, the archiver stores the time stamp as well as the
status and severity. For aiExample, we configured a high limit of 10
with a MAJOR severity. Consequently we will see a status/severity of
HIHI/MAJOR whenever the VAL field reaches the HIHI limit.
In addition to the value (VAL field), the archiver also stores certain
pieces of \INDEX{meta information}. For numeric channels, it will store the
engineering units, suggested display precision, as well as limits for
display, control, warnings, and alarms. For enumerated channels, it
stores the enumeration strings.
Applied to the aiExample record, the suggested display precision is
read from the PREC field, the limits are derived from HOPR, LOPR,
HIHI, ..., LOLO.

\NOTE You will have to consult the record reference manual or even
record source code to obtain the relations between record fields and
channel properties. The analog input record's EGU field for example
provides the engineering units for the VAL field. We could, however,
also try to archive aiExample.SCAN, that is the SCAN field of the same
record. That channel aiExample.SCAN will be an \emph{enumerated} type
with possible values ``Passive'', ``.1 second'' and so on. The EGU
field of the record no longer applies!
Another example worth considering: While HOPR defines the upper
control limit for the VAL field, what is the upper control limit if we
archive the HOPR field itself?

It is also important to remember that the archiver
--- just like any other ChannelAccess client --- does {\bfseries not} know
anything about the underlying EPICS record type of a channel. In fact
the channel might not be based on any record at all if we use a
PCAS-based server.
Given the name of an analog input record, it will store the record's
value, units and limits, that is: most of the essential record
information. Given the name of a stepper motor record, the
archiver will also store the record's value (motor position) with the
units and limits of the motor position. It will not store the
acceleration, maximum speed or other details that you might consider
essential parts of the record. To archive those, one would have to
archive them as individual channels.

\section{Sampling Options} % ---------------------------------------------
The ArchiveEngine supports these sampling mechanisms:
\begin{description}
\item[\sffamily Monitor:]
In this mode, the ArchiveEngine requests a CA monitor, i.e.\ it
subscribes to changes and we store all the values that the server
sends out. The CA server configuration determines when values are sent.

\item[\sffamily Sampled:]
In this mode, the ArchiveEngine periodically requests a value from
the CA server, e.g.\ every 30 seconds.

\item[\sffamily Sampled using monitors:]
This mode is very similar to the previous one:
The ArchiveEngine is again configured to store periodic samples,
e.g. one sample every 5 seconds. But instead of actively requesting a
value from the CA server at this rate, it establishes a monitor and
only saves a value every 5 seconds.
\end{description}

\noindent The difference between the two sampled modes is subtle but important
for performance reasons. Assume our data source changes at 1~Hz. If
we want to store a value every 30 seconds, it is most efficient to
send a 'read'-request every 30 seconds. If, on the other hand, we want
to store a value every 5 seconds, it is usually more effective to
establish a monitor, so we automatically receive updates about every
second, and simply ignore 4 of the 5 values.

When configuring a channel for the ArchiveEngine, the user only
selects either ``Monitor'' or provides a sampling rate.
The ArchiveEngine will automatically determine which mechanism to use
for sampled operation, periodic reads or monitors
(see get\_threshold configuration parameter for details).

\NOTE The values dumped into the data storage will not offer much
indication of the sampling method. In the end, we only see values with
time stamps. If for example the time stamps of the stored values
change every 20 seconds, this could be the result of a monitored
channel that happened to change every 20 seconds. We could also face a
channel that changed at 10~Hz but was only sampled every 20 seconds. 

\section{Time Stamps}
\begin{figure}[htb]
\begin{center}
\InsertImage{width=0.8\textwidth}{times}
\end{center}
\caption{\label{fig:times}Time Stamps and Sampling}
\end{figure}

Each ChannelAccess Server provides time-stamped data. An IOC for
example stamps each value when the corresponding record is
processed.  These time-stamps offer nano-second granularity. Most
applications will not require the full accuracy, but some
hardware-triggered acquisition, utilizing interrupts on a fast CPU,
might in fact put the full time stamp resolution to good use.

The ChannelArchiver as a generic tool does not know about the origin
of the time stamps, but it tries to conserve them.
Fig.~\ref{fig:times} shows the same channel, archived by different methods.
When using the ``Monitor'' method for archiving, we capture all the
changes of the channel, resulting in the data points marked by black
diamonds.
When we use scanned operation, e.g.\ every 1~second, the following
happens: About every second, the ArchiveEngine stores the current
value of the channel \emph{with its original time stamp!}.
So while the ArchiveEngine might take a sample at 10, 11, 12,
... seconds, it stores the time stamps that happen to come with the
values, and in this case those happened to be
9.9679712 seconds, 10.9894400 seconds, 11.7605488 seconds and so on.

\section{Sensible Sampling}
The data source configuration and sampling need to be coordinated.  In
fact the whole system needs to be understood. When we deal with water
tank temperatures as one example, we have to understand that the
temperature is unlikely to change rapidly. Let us assume that it only
varies within 30...60 seconds. The analog input record that reads the
temperature could be configured to scan every 2 seconds. Not because
we expect the temperature to change that quickly but mostly to provide
the operator with a warm and fuzzy feeling that we are still reading
the temperature: The operator display will show minuscule variations
in temperature every 2 seconds.  An ArchiveEngine that is meant to
capture the long-term trend of the tank temperature could then sample
the value every 60 seconds.

On the other extreme could be channels for vacuum readings along linac
cavities. The records that read them might be configured to scan as
fast as the sensing devices permit, maybe beyond 10~Hz, so that
interlocks on the IOC run as fast as possible. Their deadbands (ADEL
and MDEL) on the other hand are configured to limit the data rate that
is sent to monitoring CA clients: Only meaningful vacuum changes are
sent out, significantly reducing the amount of data sent onto the
network.  The ArchiveEngine can then be configured to monitor the
channel: During normal operation, when the vacuum is fairly stable, it
will only receive a few values, but whenever the vacuum changes
because of a leak, it will receive a detailed picture of the event.

Another example is a short-term archive that is meant to store
beam position monitor (BPM) readings for every beam pulse. The records
on the IOC can then be configured with ADEL=-1 and the ArchiveEngine
to use monitors, resulting in a value being sent onto the network and
stored in the archive even if the values did not change. The point
here is to store the time stamps and beam positions for each beam
pulse for later correlation. Needless to say that this can result in a
lot of data if the engine is kept running unattended. The preferred
mode of operation would be to run the engine only for the duration
of a short experiment.

\NOTE The scanning of the data source and the ArchiveEngine run in
parallel, they are not synchronized.
Example: If you have a record scanned every second and want to capture
every change in value, configuring the ArchiveEngine to scan every
second is {\bfseries not} advisable:
Though both the record and the ArchiveEngine would scan every
second, the two scans are not synchronized and rather unpredictable
things can happen. Instead, the "Monitor" option for the ArchiveEngine
should be used for this case.

\section{Time Stamp Correlation} 
\label{sec:timestampcorr}
We have stressed more than once that the Channel Archiver preserves
the original time stamps as sent by the CA servers.  This commonly
leads to difficulties when comparing values from different
channels. Even when two channels were served by the same IOC,
originating from records on the same scan rate, their time stamps will
slightly differ because a single CPU cannot scan several channels at
exactly the same time.  Tab.~\ref{tab:ABtimes} shows one example.

\begin{table}[htbp]
  \begin{center}
    \begin{minipage}[t]{0.49\textwidth}
      \begin{tabular}[t]{l|l}
        Time               & A         \\
        \hline
        17:02:28.700986000 & 0.0718241 \\
        17:02:37.400964000 & 0.0543581 \\
        ...
      \end{tabular}
    \end{minipage}%
    \begin{minipage}[t]{0.49\textwidth}
      \begin{tabular}[t]{l|l}
        Time               & B         \\
        \hline
        17:02:28.701046000 & -0.086006 \\
        17:02:37.510961000 & -0.111776 \\
        ...
      \end{tabular}
    \end{minipage}%
    \caption{Example Time Stamps for two Channels A and B.}
    \label{tab:ABtimes}
  \end{center}
\end{table}

\noindent When we try to export this data in what we call
\INDEX{raw spreadsheet format}, a problem arises:
Even though the two channels' time stamps are close, they do
not match, resulting in a spreadsheet as shown in
Tab.~\ref{tab:ABraw}. Whenever one channel has a value, the ``other''
channel has none and vice versa.  This spreadsheet does not yield
itself to further analysis; calculations like $A-B$ will always yield
\INDEX{'\#N/A'} since either A or B is undefined.


\begin{table}[htbp]
  \begin{center}
    \begin{tabular}[t]{l|l|l}
      Time                         & A         & B         \\
      \hline
      3/22/2000 17:02:28.700986000 & 0.0718241 & ---       \\
      3/22/2000 17:02:28.701046000 & ---       & -0.086006 \\
      3/22/2000 17:02:37.400964000 & 0.0543581 & ---       \\
      3/22/2000 17:02:37.510961000 & ---       & -0.111776 \\
      ...
    \end{tabular}
    \caption{Spreadsheet for raw Channels A and B.}
    \label{tab:ABraw}
  \end{center}
\end{table}

\noindent There are several ways to deal with this. One is what we call
\INDEX{Staircase Interpolation} or \INDEX{Filling}: Whenever there is
no current value for a channel, we re-use the previous value. This is
often perfectly acceptable because the CA server will only
send us updates whenever a channel changes beyond the configured
deadband. So if we monitored a channel and did not receive a new
value, this means that the previous value is still valid (at least
within the configured deadband).  In the case of scanned channels we
have no idea how a channel behaved in between scans, but if we e.g.\
look at water temperatures, it might be safe to assume that the
previous value is still ``close enough''.
Table~\ref{tab:ABstair} shows the previously discussed data subjected
to staircase interpolation. Note that in this example there is no
initial value for channel B, resulting in one empty spreadsheet
cell. From then on, however, there are always values for both
channels, because any missing samples are filled by repeating the
previous one.

\NOTE While table~\ref{tab:ABstair} marks the filled values by
printing them in italics, spreadsheets generated by archive retrieval
tools will not accent the filled values in any way, so care must be taken: Those
filled values carry artificial time stamps. If you depend on the
original time stamps in order to synchronize certain events, you must
not use any form of interpolation but always retrieve the raw data. 

\begin{table}[htbp]
  \begin{center}
    \begin{tabular}[t]{l|l|l}
      Time                         & A         & B         \\
      \hline
      3/22/2000 17:02:28.700986000 & 0.0718241 & ---       \\
      3/22/2000 17:02:28.701046000 & \textit{0.0718241}      & -0.086006 \\
      3/22/2000 17:02:37.400964000 & 0.0543581 & \textit{-0.086006} \\
      3/22/2000 17:02:37.510961000 & \textit{0.0543581} & -0.111776 \\
      ...
    \end{tabular}
    \caption{Spreadsheet for Channels A and B with Staircase
      Interpolation (``Filled'' values shown in italics).}
    \label{tab:ABstair}
  \end{center}
\end{table}
