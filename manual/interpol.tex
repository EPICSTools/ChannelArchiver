% interpol.tex
\section{Time Stamp Correlation} \label{sec:timestampcorr}
We have stressed more than once that the Channel Archiver preserves
the original time stamps as sent by the CA servers.  This commonly
leads to difficulties when comparing values from different
channels. The following subsections investigate the issue in more
detail and show several ways of manipulating the data in order to
allow data reduction and cross-channel comparisons.
In short, the options described in the following subsections are:
\begin{description}
\item[\sffamily Raw Data:]
  Provides every archived sample ``as is''.
\item[\sffamily Staircase/Filling:]
  Duplicates samples to form a spreadsheet.
\item[\sffamily Linear/Averaged Interpolation:]
  Provides exactly the requested number of data points by
  interpolating or averaging the raw samples.
\item[\sffamily Plot Binning:]
  Reduces the number of samples for plotting.
\end{description}

\subsection{``Raw'' Data} \label{sec:rawdata}
Even when two channels were served by the same IOC, and originating from
records on the same scan rate, their time stamps will slightly differ
because a single CPU cannot scan several channels at exactly the same
time.  Tab.~\ref{tab:ABtimes} shows one example.

\begin{table}[htbp]
  \begin{center}
    \begin{minipage}[t]{0.49\textwidth}
      \sffamily
      \begin{tabular}[t]{l|l}
        Time               & A         \\
        \hline
        17:02:28.700986000 & 0.0718241 \\
        17:02:37.400964000 & 0.0543581 \\
        ...
      \end{tabular}
    \end{minipage}%
    \begin{minipage}[t]{0.49\textwidth}
      \sffamily
      \begin{tabular}[t]{l|l}
        Time               & B         \\
        \hline
        17:02:28.701046000 & -0.086006 \\
        17:02:37.510961000 & -0.111776 \\
        ...
      \end{tabular}
    \end{minipage}%
    \caption{Example Time Stamps for two Channels A and B.}
    \label{tab:ABtimes}
  \end{center}
\end{table}

\noindent When we try to export this data in what we call \INDEX{raw
spreadsheet format}, a problem arises: Even though the two channels'
time stamps are close, they do not match, resulting in a spreadsheet
as shown in Tab.~\ref{tab:ABraw}. Whenever one channel has a value,
the other channel has none and vice versa.  This spreadsheet does
not yield itself to further analysis; calculations like $A-B$ will
always yield \INDEX{'\#N/A'} since either A or B is undefined.

\begin{table}[htbp]
  \begin{center}
    \sffamily
    \begin{tabular}[t]{l|l|l}
      Time                         & A         & B         \\
      \hline
      3/22/2000 17:02:28.700986000 & 0.0718241 & ---       \\
      3/22/2000 17:02:28.701046000 & ---       & -0.086006 \\
      3/22/2000 17:02:37.400964000 & 0.0543581 & ---       \\
      3/22/2000 17:02:37.510961000 & ---       & -0.111776 \\
      ...
    \end{tabular}
    \caption{Spreadsheet for raw Channels A and B.}
    \label{tab:ABraw}
  \end{center}
\end{table}

\subsection{``Before or at'' Interpretation of Start Times}
 \label{sec:starttime}
When you invoke a retrieval tool with a certain start time, the
archive will rarely contain a sample for that exact start time. As an
example, you might ask for a start time of ``07:00:00'' on some date. Not
because you expect to find a sample with that exact time stamp, but
because you want to look at data from the beginning of that day's
operations shift, which nominally began at 7am.

The software underlying all retrieval tools anticipates this scenario
by interpreting all start times as ``before or at''. Given a start time
of ``07:00:00'', it returns the last sample before that start
time, unless an exact match is found. So in case a sample for the
exact start time exists, it will of course be returned. But if the
archive contains no such sample, the previous sample is returned.

Applied to Tab.~\ref{tab:ABraw}, channel A, you would get the samples
shown in there not only if you asked for ``17:02:28.700986000'', the
exact start time, but also if you asked for ``17:02:30''.
It is left to the end user to decide whether that previous sample is
still useful at the requested start time, if it's ``close enough'', or
if it needs to be ignored.

\subsection{Staircase Interpolation/Filling} \label{sec:filling}
There are several ways of mapping channels onto matching time
stamps. One is what we call \INDEX{Staircase Interpolation} or
\INDEX{Filling}: Whenever there is no current value for a channel, we
re-use the previous value. This is often perfectly acceptable because
the CA server will only send updates whenever a channel changes beyond
the configured deadband. So if we monitored a channel and did not
receive a new value, this means that the previous value is still valid
--- at least within the configured deadband. In the case of scanned
channels we have no idea how a channel behaved in between scans, but
if we e.g.\ look at water temperatures, it might be safe to assume
that the previous value is still ``close enough''.
Table~\ref{tab:ABstair} shows the previously discussed data subjected
to staircase interpolation. Note that in this example there is no
initial value for channel B, resulting in one empty spreadsheet
cell. From then on, however, there are always values for both
channels, because any missing samples are filled by repeating the
previous one.  Because of the interpretation of start times explained
in section \ref{sec:starttime}, you would get the result in
 Tab.\ \ref{tab:ABstair} not only if you asked for values beginning
``3/22/2000 17:02:28.700986000'', but also when you asked for
e.g. ``17:02:30'': Since neither channel A nor B have a sample for that
exact time stamp, the retrieval library would select the
preceding sample for each channel, resulting in the output shown in 
Tab.\ \ref{tab:ABstair}.

\NOTE While table~\ref{tab:ABstair} marks the filled values by
printing them in italics, spreadsheets generated by archive retrieval
tools will not accent the filled values in any way, so care must be
taken: Those filled values carry artificial time stamps. If you depend
on the original time stamps in order to synchronize certain events,
you must not use any form of interpolation but always retrieve the raw
data. 

\begin{table}[htbp]
  \begin{center}
    \sffamily
    \begin{tabular}[t]{l|l|l}
      Time                         & A         & B         \\
      \hline
      3/22/2000 17:02:28.700986000 & 0.0718241 & ---       \\
      3/22/2000 17:02:28.701046000 & \textit{0.0718241}      & -0.086006 \\
      3/22/2000 17:02:37.400964000 & 0.0543581 & \textit{-0.086006} \\
      3/22/2000 17:02:37.510961000 & \textit{0.0543581} & -0.111776 \\
      ...
    \end{tabular}
    \caption{Spreadsheet for Channels A and B with Staircase
      Interpolation; ``filled'' values shown in italics.}
    \label{tab:ABstair}
  \end{center}
\end{table}

You did of course notice that the staircase interpolation does not
reduce the amount of data. Quite the opposite: In the above examples,
channels A and B each had 2 values. With staircase interpolation, we
don't get a spreadsheet with 2 lines of data but 4 lines of data.  The
main advantage of filling lies is the preservation of original time stamps.

\subsection{Linear/Averaged Interpolation}  \label{sec:lininterpol}
Linear interpolation generates artificial values from the raw
data. This can be used to reduce the amount of data: For a summary of
the last day, it might be sufficient to look at one value every 30
minutes, even though the archive could contain much more data.
Another aspect is partly cosmetic and partly a matter of convenience:
When we look at Tab.~\ref{tab:ABstair}, we find rather odd looking
time stamps. While these reflect the real time stamps that the
ArchiveEngine received from the ChannelAccess server, it is often
preferable to deal with data that has time stamps which are nicely
aligned, for example every 10 seconds: 11:20:00, 11:20:10, 11:20:20,
11:20:30 and so on.

\begin{figure}[htb]
\begin{center}
\medskip
\InsertImage{width=\textwidth}{interpol}
\end{center}
\caption{\label{fig:interpol}Linear Interpolation and Averaging, see text.}
\end{figure}

\noindent When we select ``Linear Interpolation'', the archive retrieval code
will actually automatically switch between three types of
interpolation: \INDEX{Linear Interpolation}, \INDEX{Averaging} and the
Staircase Interpolation that we already presented in the preceding
subsection. All methods will modify the original time stamps and data
in order to transform them onto the requested periodic time stamps.  

In the following, refer to fig.~\ref{fig:interpol}, and compare the
raw samples shown in there with the result of interpolation.  When
linear interpolation onto e.g.\ multiples of 10 seconds is requested,
the following happens for each interval or ``time slot'' of 10 seconds
within the queried time range:
\begin{itemize}
\item If there was up to one scalar value of type double,
  long, int or short, either inside or preceding the current time
  slot, followed by at least one value after the current time slot,
  linear interpolation is used to determine the approximate value at
  the end of the time slot. Special values like ``Disconnected'' or
  ``Archiver Off'', that is samples that have no numeric data, are not
  interpolated.

  Most of the red squares in fig.~\ref{fig:interpol} exemplify this
  behavior: For time slots 11:20:00, 11:20:10, 11:20:20, ..., 11:21:10
  there is always exactly one raw value before and after the time
  slot, so linear interpolation is used to determine the approximate
  value at the time slots.
  The red squares do in fact exactly fall onto the connecting lines
  between raw samples if you consider the full time stamps, but the
  plotting program chosen to produce fig.~\ref{fig:interpol} rounds
  down to full seconds.
  The gap from 11:21:10 to 11:21:40 results from ``Disconnected''
  samples in the gap which cannot be interpolated.

\item Averaging is used if several values fall into the
  current time slot and the data type allows averaging,
  i.e.\ it's a scalar double, long, int or short.
  In this case, the retrieval reports the average over
  the values in the current time slot. For a time stamp
  it uses the center of the time slot.

  The blue and green stars in fig.~\ref{fig:interpol} result from
  averaging: Since more than one sample falls into the time slots
  which are 30 respectively 60 seconds wide, those samples are
  averaged and the resulting value for e.g.\ 60 second interpolation
  is reported in the middle of the 60-second time slots: 11:20:30, 11:21:30,
  11:22:30, etc. Note that the averaging also covers time slots that
  contain special non-values like the slot from 11:21:00 to 11:22:00:
  While there is a ``disconnected'' region in there, the remaining 5
  raw samples are used for averaging.

\item As a fallback, staircase interpolation is used for arrays or
  scalars of type string, char or enumerated, or when the single
  preceding and following sample is a non-value like ``disconnected''
  or ``archiver off''. In short: cases that prohibit linear
  interpolation and averaging.  Staircase means in this case that the
  last value before a time slot is extrapolated onto the time slot.
  That's usually valid because we either sampled a slow changing
  channel, so the previous value is still good enough; or we archived
  on change and no change means the previous data is still valid.
  (While in fact one could interpolate or average certain arrays, we
  don't because for one that's expensive. In addition, EPICS arrays
  often contain more than just waveform elements: They're
  used to transfer structures.)
\end{itemize}

\subsection{Plot-Binning} \label{sec:plotbinning}
This method is meant for plotting, providing data that --- when
plotted --- looks exactly like the raw data, albeit significantly
reducing the number of data points and hence speeding up the plot.  To
accomplish this, the data is binned. For example, the time span of one
day, 24~hours, can be divided into 800 sections, each of which covers 108
seconds. Each of those sections is called a ``Bin''. The raw samples
for the day are then investigated as follows:
\begin{itemize}
\item If there is no sample for the time span of a bin, the bin
  remains empty.
\item If there is one sample, it is placed in the bin.
\item If there are two samples, they are placed in the bin.
\item If there are more than two samples, the first and last one
  are placed in the bin. In addition, two artificial samples are
  created with a time stamp right between the first and last sample.
  One contains the minimum, the other the maximum of all raw samples
  who's time stamps fall into the bin. They are presented to the user
  in the sequence initial, minimum, maximum, final.
\end{itemize}

Note that the ``before or at'' interpretation of start times does not
apply for Plot-Binning: The exact start time of the request is used
to determine the beginning of the first bin, and only samples within
each bin are considered, there is no interpolation onto bin-boundaries.
In general, the use of $N$ bins can result in up to 4$N$ data points,
since each bin might provide an initial, minimum, maximum and final value.
In most cases, this results in a significant data
reduction. As long as we plot this such that the width of the plot in
pixes is close to the number of bins, there is no visual difference
between the raw data plot and the binned plot.  Typical numbers for
$N$ are around the width of a computer screen in pixels, that is
800\ldots 1200.  For the special case were 3 raw values happen to fall
into every bin, we will get 4$N$ instead of 4$N$ data points. For
typical $N$, that is a slight but not dramatic increase in retrieval
or plotting time. It is neglectable compared to the fact that binning
guarantees an upper limit of 4$N$ data points, no matter how many raw
samples there are.
